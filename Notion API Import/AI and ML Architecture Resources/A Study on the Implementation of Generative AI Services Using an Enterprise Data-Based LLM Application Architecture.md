---
title: A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture
database: AI and ML Architecture Resources
created: "2023-11-30T21:21:00.000Z"
updated: "2023-12-01T03:37:00.000Z"
notion_id: d6b67863-c147-43ce-bc5d-d73ab01bddc5
notion_url: "https://www.notion.so/A-Study-on-the-Implementation-of-Generative-AI-Services-Using-an-Enterprise-Data-Based-LLM-Applicati-d6b67863c14743cebc5dd73ab01bddc5"
code_availability: The paper discusses implementation methods, suggesting potential availability of an open-source implementation or illustrative codes.
impact_factor: 
dataset_used: Specific datasets are not explicitly mentioned; the study likely involves enterprise-specific datasets relevant to LLM applications.
followup_actions: Further exploration and integration of the RAG model into enterprise systems, and adaptation to specific business needs.
technology_domain: Generative AI, Language Models, Information Retrieval, AI in Enterprise Applications
publication_date: *3 Sep 2023*
methodology: Retrieval-Augmented Generation (RAG) model, fine-tuning of Large Language Models (LLM), direct document integration.
abstractsummary: This study introduces a Retrieval-Augmented Generation (RAG) model for implementing generative AI services using an enterprise data-based Large Language Model (LLM) application architecture. It addresses information scarcity and proposes remedies by harnessing LLM capabilities. The focus is on fine-tuning techniques and direct document integration to enhance LLMs, especially the development of the RAG model to improve information storage and retrieval for better content generation.
notes: This paper explores the use of a Retrieval-Augmented Generation (RAG) model in an enterprise context, focusing on enhancing Large Language Models (LLMs) through fine-tuning and direct document integration. It addresses the challenges of data scarcity and hallucinations in generative AI, proposing the RAG model as a solution to improve the quality of content generation. The study is particularly relevant for businesses looking to implement AI-driven content generation and information retrieval systems, offering insights into the practical application of advanced AI models in real-world scenarios.
attachments: 
application_to_projects: Applicable in enterprise AI services for tasks requiring generative AI capabilities, particularly where direct data integration and enhanced information retrieval are beneficial.
tags: Generative AI, LLM, RAG, LangChain, Embedding Vector Store
relevance_score: 
sourcelink: "[https://arxiv.org/abs/2309.01105](https://arxiv.org/abs/2309.01105)"
resultsfindings: The RAG model enhances information storage and retrieval, improving content generation by addressing data insufficiency and hallucination issues in LLMs.
authors: Cheonsu Jeong
cited_by: 
contributors: Cheonsu Jeong is the main contributor; additional contributions would be specific to your team members who interact with this paper.
---

